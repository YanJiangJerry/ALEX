{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Imports"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import re\n","import csv\n","import random\n","import pandas as pd\n","from sklearn.utils import shuffle\n","from collections import Counter\n","\n","from imblearn.over_sampling import RandomOverSampler\n","from imblearn.under_sampling import RandomUnderSampler\n","from textattack.transformations import WordSwapRandomCharacterDeletion\n","from textattack.transformations import WordSwapQWERTY\n","from textattack.transformations import CompositeTransformation\n","from textattack.transformations import WordSwapChangeLocation\n","from textattack.transformations import WordSwapChangeName\n","from textattack.transformations import WordSwapChangeNumber\n","from textattack.transformations import WordSwapContract\n","from textattack.transformations import WordSwapWordNet\n","from textattack.transformations import WordSwapRandomCharacterSubstitution\n","from textattack.constraints.pre_transformation import RepeatModification\n","from textattack.constraints.pre_transformation import StopwordModification\n","from textattack.augmentation import Augmenter"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Xuli_EdFD4pr"},"source":["### Data Preprocessing\n","\n","* Read training dataset files\n","* Join datasets in a single DataFrame\n","* Lowercase text (optional)\n","* Replacing \"\\&amp;\" for \"&\"\n","* Augment dataset\n","* Save augmented dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.read_csv('4/t.csv',encoding='latin')\n","df = df.iloc[1:]\n","df = shuffle(df)\n","\n","train_size = int(0.7 * len(df))\n","val_size = int(0.2 * len(df))\n","test_size = len(df) - train_size - val_size\n","train_data = df[:train_size]\n","val_data = df[train_size:train_size + val_size]\n","test_data = df[train_size + val_size:]\n","train_data.columns = ['text', 'label']\n","val_data.columns = ['text', 'label']\n","test_data.columns = ['text', 'label']\n","\n","train_data.to_csv('4/train6.csv', index=False ,encoding='latin')\n","val_data.to_csv('4/validate6.csv', index=False,encoding='latin')\n","test_data.to_csv('4/test6.csv', index=False,encoding='latin')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1296,"status":"ok","timestamp":1665528850773,"user":{"displayName":"Edgar Morais","userId":"09708779788321972011"},"user_tz":-60},"id":"SpfJEZ1uC_h4"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\yan\\AppData\\Local\\Temp\\ipykernel_37996\\2436515153.py:17: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df[\"text\"][i] = df[\"text\"][i].replace(\"&amp;\", \"&\")\n"]}],"source":["tweet_file = \"4/train.csv\"\n","lowercase = False\n","\n","tweet_df = pd.read_csv(tweet_file, delimiter=',', index_col=False, encoding='latin1')\n","d = {\"label\":tweet_df['label'], \"text\":tweet_df['text']}\n","\n","df = pd.DataFrame(data = d)\n","for i in range(0, len(df)-1):\n","  if \"&amp;\" in df[\"text\"][i]:\n","    df[\"text\"][i] = df[\"text\"][i].replace(\"&amp;\", \"&\")\n","  if lowercase:\n","    df[\"text\"][i] = df[\"text\"][i].lower()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["0       I have never seen a therapist at any point in ...\n","1       Seriously my man, you got to understand that s...\n","2       Hey, I saw your post a couple of weeks ago on ...\n","3       Maybe if your feeling like that again in a sim...\n","4       I'm 20 and I would definitely be interested. I...\n","                              ...                        \n","3144    I am going to be a freshman in college this fa...\n","3145    Meditation, CBT therapy, calming oils, CBD. Oc...\n","3146    I do the same shit dude. I¡¯m in pretty consis...\n","3147    i¡¯ve had medication prescribed to me because ...\n","3148    I¡¯m 22 and wonder if it¡¯ll get better for me...\n","Name: text, Length: 3149, dtype: object"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["tweet_df['text']"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1665528850774,"user":{"displayName":"Edgar Morais","userId":"09708779788321972011"},"user_tz":-60},"id":"Mbsg8dPzjnrV","outputId":"5f4115d9-6e0a-4e90-a6af-3af53a643908"},"outputs":[{"data":{"text/plain":["0       I have never seen a therapist at any point in ...\n","1       Seriously my man, you got to understand that s...\n","2       Hey, I saw your post a couple of weeks ago on ...\n","3       Maybe if your feeling like that again in a sim...\n","4       I'm 20 and I would definitely be interested. I...\n","                              ...                        \n","3144    I am going to be a freshman in college this fa...\n","3145    Meditation, CBT therapy, calming oils, CBD. Oc...\n","3146    I do the same shit dude. I¡¯m in pretty consis...\n","3147    i¡¯ve had medication prescribed to me because ...\n","3148    I¡¯m 22 and wonder if it¡¯ll get better for me...\n","Name: text, Length: 3149, dtype: object"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["X = df.text\n","X"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1665528850775,"user":{"displayName":"Edgar Morais","userId":"09708779788321972011"},"user_tz":-60},"id":"QXKa3VxRY8V5","outputId":"66dbaa52-1c4d-4b9c-a848-85e29e91cec6"},"outputs":[{"data":{"text/plain":["0       0\n","1       0\n","2       0\n","3       1\n","4       1\n","       ..\n","3144    1\n","3145    1\n","3146    1\n","3147    1\n","3148    0\n","Name: label, Length: 3149, dtype: int64"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["y = df.label\n","y"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1665528850776,"user":{"displayName":"Edgar Morais","userId":"09708779788321972011"},"user_tz":-60},"id":"DrgcpRbFdwYK","outputId":"989d140e-b349-4e58-91d2-fa2c81dea89c"},"outputs":[{"name":"stdout","output_type":"stream","text":["There are  1205 positive examples in this dataset.\n","There are  1944 negative examples in this dataset.\n"]}],"source":["print(\"There are \", len(df[df[\"label\"]==1]) , \"positive examples in this dataset.\")\n","print(\"There are \", len(df[df[\"label\"]==0]), \"negative examples in this dataset.\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"9HOH8HEsFPAs"},"source":["### Augmentation\n","\n","* Use following transformations:\n","  * Random character swap\n","  * Character swap by adjacent QWERTY keyboard characters\n","  * Perform contractions (For example: \"I am\"->\"I'm\")\n","  * Swap words by Word Net synonyms "]},{"cell_type":"code","execution_count":10,"metadata":{"id":"1x_FQGcI37Vg"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package omw-1.4 to\n","[nltk_data]     C:\\Users\\yan\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]},{"name":"stdout","output_type":"stream","text":["705 tweets augmented.\n","Could not augment  500 tweets.\n"]}],"source":["transformation = CompositeTransformation([WordSwapRandomCharacterSubstitution(), WordSwapQWERTY(), WordSwapWordNet(), WordSwapContract()])\n","constraints = [RepeatModification(), StopwordModification()]\n","augmenter = Augmenter(transformation=transformation, constraints=constraints, pct_words_to_swap=0.1, transformations_per_example=2)\n","print_var = 1\n","print_count = 0\n","\n","i = 0\n","neg = 0\n","for index, row in df.iterrows():\n","  if(row[\"label\"]==1):\n","    try:\n","      text = re.sub('@\\w+', '@', row[\"text\"])\n","      text = text.replace(\"'\", \"\")\n","      l = augmenter.augment(text)\n","      for n in range(len(l)):\n","        l[n] = l[n].replace(\"@\", \"@USER____\")\n","      new_serie = pd.Series(l)\n","      X = pd.concat([X, new_serie], ignore_index=True)\n","      ade_serie = pd.Series([1]*2)\n","      y = pd.concat([y, ade_serie], ignore_index=True)\n","      i = i + 1\n","    except IndexError:\n","      neg = neg + 1\n","    \n","print(i, \"tweets augmented.\")\n","print(\"Could not augment \", neg, \"tweets.\")"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"Xf_WX8k24UWi"},"outputs":[{"data":{"text/plain":["Counter({0: 1944, 1: 2615})"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["Counter(y)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"v2scjhkxMkfJ"},"outputs":[],"source":["with open(\"4/aug1.tsv\", 'wt', encoding='latin') as out_file:\n","    tsv_writer = csv.writer(out_file, delimiter='\\t')\n","    tsv_writer.writerow(['text', 'label'])\n","    for i in range(len(X)):\n","      tsv_writer.writerow([X[i], y[i]])"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["There are  2615 positive examples in this dataset.\n","There are  1944 negative examples in this dataset.\n"]}],"source":["import pandas as pd\n","import csv\n","augument3 = \"4/aug1.tsv\"\n","df3 = pd.read_csv(augument3, sep='\\t', quoting=csv.QUOTE_NONE, encoding='latin')\n","print(\"There are \", len(df3[df3[\"label\"]==1]) , \"positive examples in this dataset.\")\n","print(\"There are \", len(df3[df3[\"label\"]==0]), \"negative examples in this dataset.\")"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["X3 = df3.text.values\n","y3 = df3.label.values"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"H6eJeJRFE5rE"},"source":["### Resample to make each class same number of samples"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"DYmzg6oJFBCS"},"outputs":[{"name":"stdout","output_type":"stream","text":["5230\n"]},{"data":{"text/plain":["Counter({0: 2615, 1: 2615})"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["oversampler = RandomOverSampler(sampling_strategy=1)\n","X_oversampled, y_oversampled = oversampler.fit_resample(X.to_numpy().reshape(-1,1), y)\n","\n","print(len(X_oversampled))\n","Counter(y_oversampled)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"PIiKAyrjfhCC"},"outputs":[],"source":["with open(\"4/aug2.tsv\", 'wt', encoding='latin') as out_file:\n","    tsv_writer = csv.writer(out_file, delimiter='\\t')\n","    tsv_writer.writerow(['text', 'label'])\n","    for i in range(len(X_oversampled)):\n","      tsv_writer.writerow([X_oversampled[i][0], y_oversampled[i]])"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["There are  2615 positive examples in this dataset.\n","There are  2615 negative examples in this dataset.\n"]}],"source":["df4 = pd.read_csv('4/aug2.tsv', sep='\\t', quoting=csv.QUOTE_NONE, encoding='latin')\n","print(\"There are \", len(df4[df4[\"label\"]==1]) , \"positive examples in this dataset.\")\n","print(\"There are \", len(df4[df4[\"label\"]==0]), \"negative examples in this dataset.\")"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["X = df4.text\n","y = df4.label"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"T8OvC_ASyuzZ"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package omw-1.4 to\n","[nltk_data]     C:\\Users\\yan\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]},{"name":"stdout","output_type":"stream","text":["4052 tweets augmented.\n","Could not augment  1178 tweets.\n"]}],"source":["transformation = CompositeTransformation([WordSwapRandomCharacterSubstitution(), WordSwapQWERTY(), WordSwapWordNet(), WordSwapContract()])\n","constraints = [RepeatModification(), StopwordModification()]\n","augmenter = Augmenter(transformation=transformation, constraints=constraints, pct_words_to_swap=0.1, transformations_per_example=1)\n","print_var = 1\n","print_count = 0\n","\n","i = 0\n","neg = 0\n","for index, row in df4.iterrows():\n","  if(row[\"label\"]==1):\n","    try:\n","      text = re.sub('@\\w+', '@', row[\"text\"])\n","      text = text.replace(\"'\", \"\")\n","      l = augmenter.augment(text)\n","      for n in range(len(l)):\n","        l[n] = l[n].replace(\"@\", \"@USER____\")\n","      new_serie = pd.Series(l)\n","      X = pd.concat([X, new_serie], ignore_index=True)\n","      ade_serie = pd.Series([1])\n","      y = pd.concat([y, ade_serie], ignore_index=True)\n","      i = i + 1\n","    except IndexError:\n","      neg = neg + 1\n","  else:\n","    try:\n","      text = re.sub('@\\w+', '@', row[\"text\"])\n","      text = text.replace(\"'\", \"\")\n","      l = augmenter.augment(text)\n","      for n in range(len(l)):\n","        l[n] = l[n].replace(\"@\", \"@USER____\")\n","      new_serie = pd.Series(l)\n","      X = pd.concat([X, new_serie], ignore_index=True)\n","      ade_serie = pd.Series([0])\n","      y = pd.concat([y, ade_serie], ignore_index=True)\n","      i = i + 1\n","    except IndexError:\n","      neg = neg + 1\n","        \n","print(i, \"tweets augmented.\")\n","print(\"Could not augment \", neg, \"tweets.\")"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"ccwpRGshyuzj"},"outputs":[{"data":{"text/plain":["Counter({0: 4633, 1: 4649})"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["Counter(y)"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["combined_data1 = list(zip(X, y))\n","random.shuffle(combined_data1)\n","shuffled_X1, shuffled_y1 = zip(*combined_data1)\n","\n","with open(\"4/finalaugshuffle1.tsv\", 'wt', encoding='latin', newline='') as out_file:\n","    tsv_writer = csv.writer(out_file, delimiter='\\t')\n","    tsv_writer.writerow(['text', 'label'])\n","    for i in range(len(shuffled_X1)):\n","      tsv_writer.writerow([shuffled_X1[i], shuffled_y1[i]])"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["combined_data1 = list(zip(X, y))\n","random.shuffle(combined_data1)\n","shuffled_X1, shuffled_y1 = zip(*combined_data1)\n","\n","with open(\"4/finalaugshuffle1utf.tsv\", 'wt', encoding='utf-8', newline='') as out_file:\n","    tsv_writer = csv.writer(out_file, delimiter='\\t')\n","    tsv_writer.writerow(['text', 'label'])\n","    for i in range(len(shuffled_X1)):\n","      tsv_writer.writerow([shuffled_X1[i], shuffled_y1[i]])"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"Zpn3sLXPzAaQ"},"outputs":[{"name":"stdout","output_type":"stream","text":["9266\n"]},{"data":{"text/plain":["Counter({0: 4633, 1: 4633})"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["oversampler = RandomUnderSampler(sampling_strategy=1)\n","X_oversampled, y_oversampled = oversampler.fit_resample(X.to_numpy().reshape(-1,1), y)\n","\n","print(len(X_oversampled))\n","Counter(y_oversampled)"]},{"cell_type":"markdown","metadata":{},"source":["#### Save various version becasue some encoding may has invalid characters"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["combined_data = list(zip(X_oversampled, y_oversampled))\n","random.shuffle(combined_data)\n","shuffled_X, shuffled_y = zip(*combined_data)\n","\n","with open(\"4/finalaugshuffle2.tsv\", 'wt', encoding='latin', newline='') as out_file:\n","    tsv_writer = csv.writer(out_file, delimiter='\\t')\n","    tsv_writer.writerow(['text', 'label'])\n","    for i in range(len(shuffled_X)):\n","        tsv_writer.writerow([shuffled_X[i][0], shuffled_y[i]])"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["combined_data = list(zip(X_oversampled, y_oversampled))\n","random.shuffle(combined_data)\n","shuffled_X, shuffled_y = zip(*combined_data)\n","\n","with open(\"4/finalaugshuffle2uef.tsv\", 'wt', encoding='utf-8', newline='') as out_file:\n","    tsv_writer = csv.writer(out_file, delimiter='\\t')\n","    tsv_writer.writerow(['text', 'label'])\n","    for i in range(len(shuffled_X)):\n","        tsv_writer.writerow([shuffled_X[i][0], shuffled_y[i]])"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"HAY9g_58zAaV"},"outputs":[],"source":["# Save oversampled dataset\n","with open(\"augmented_oversampled_training4.tsv\", 'wt', encoding='utf-8') as out_file:\n","    tsv_writer = csv.writer(out_file, delimiter='\\t')\n","    tsv_writer.writerow(['text', 'label'])\n","    for i in range(len(X_oversampled)):\n","      tsv_writer.writerow([X_oversampled[i][0], y_oversampled[i]])"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"1D4Sv5bbhLEw"},"outputs":[{"name":"stdout","output_type":"stream","text":["5531\n"]},{"data":{"text/plain":["Counter({0: 2798, 1: 2733})"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["print(len(X))\n","Counter(y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ASsWJpb6hpqk"},"outputs":[],"source":["# Save dataset\n","with open(\"merged_training_dataset.tsv\", 'wt', encoding='utf-8') as out_file:\n","    tsv_writer = csv.writer(out_file, delimiter='\\t')\n","    tsv_writer.writerow(['text', 'label', 'start', 'end', 'span', 'med_id'])\n","    for i in range(len(X)):\n","      tsv_writer.writerow([X[i], y[i]])"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO6+GTLvZaa89JuxCGat1Ig","collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.11 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}}},"nbformat":4,"nbformat_minor":0}
