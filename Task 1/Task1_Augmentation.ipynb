{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Imports"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import re\n","import csv\n","import random\n","import pandas as pd\n","from sklearn.utils import shuffle\n","from collections import Counter\n","\n","from imblearn.over_sampling import RandomOverSampler\n","from imblearn.under_sampling import RandomUnderSampler\n","from textattack.transformations import WordSwapRandomCharacterDeletion\n","from textattack.transformations import WordSwapQWERTY\n","from textattack.transformations import CompositeTransformation\n","from textattack.transformations import WordSwapChangeLocation\n","from textattack.transformations import WordSwapChangeName\n","from textattack.transformations import WordSwapChangeNumber\n","from textattack.transformations import WordSwapContract\n","from textattack.transformations import WordSwapWordNet\n","from textattack.transformations import WordSwapRandomCharacterSubstitution\n","from textattack.constraints.pre_transformation import RepeatModification\n","from textattack.constraints.pre_transformation import StopwordModification\n","from textattack.augmentation import Augmenter"]},{"cell_type":"markdown","metadata":{},"source":["### Data Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.read_csv('1/train.tsv', sep='\\t', quoting=csv.QUOTE_NONE,encoding='latin')\n","df = df.iloc[1:]\n","df = df.drop(df.columns[0], axis=1)\n","df = shuffle(df)\n","train_size = int(0.7 * len(df))\n","val_size = int(0.2 * len(df))\n","test_size = len(df) - train_size - val_size\n","\n","train_data = df[:train_size]\n","val_data = df[train_size:train_size + val_size]\n","test_data = df[train_size + val_size:]\n","\n","train_data.columns = ['text', 'label']\n","val_data.columns = ['text', 'label']\n","test_data.columns = ['text', 'label']\n","\n","train_data.to_csv('1/train.csv', index=False ,encoding='latin')\n","val_data.to_csv('1/validate.csv', index=False,encoding='latin')\n","test_data.to_csv('1/test.csv', index=False,encoding='latin')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1296,"status":"ok","timestamp":1665528850773,"user":{"displayName":"Edgar Morais","userId":"09708779788321972011"},"user_tz":-60},"id":"SpfJEZ1uC_h4"},"outputs":[],"source":["tweet_file = \"1/train.csv\"\n","lowercase = False\n","tweet_df = pd.read_csv(tweet_file, delimiter=',', index_col=False, encoding='latin1')\n","d = {\"label\":tweet_df['label'], \"text\":tweet_df['text']}\n","\n","df = pd.DataFrame(data = d)\n","for i in range(0, len(df)-1):\n","  if \"&amp;\" in df[\"text\"][i]:\n","    df[\"text\"][i] = df[\"text\"][i].replace(\"&amp;\", \"&\")\n","  if lowercase:\n","    df[\"text\"][i] = df[\"text\"][i].lower()"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1665528850776,"user":{"displayName":"Edgar Morais","userId":"09708779788321972011"},"user_tz":-60},"id":"DrgcpRbFdwYK","outputId":"989d140e-b349-4e58-91d2-fa2c81dea89c"},"outputs":[{"name":"stdout","output_type":"stream","text":["There are  951 positive examples in this dataset.\n","There are  4648 negative examples in this dataset.\n"]}],"source":["print(\"There are \", len(df[df[\"label\"]==1]) , \"positive examples in this dataset.\")\n","print(\"There are \", len(df[df[\"label\"]==0]), \"negative examples in this dataset.\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"9HOH8HEsFPAs"},"source":["### Data Augmentation\n","\n","* Use following transformations:\n","  * Random character swap\n","  * Character swap by adjacent QWERTY keyboard characters\n","  * Perform contractions (For example: \"I am\"->\"I'm\")\n","  * Swap words by Word Net synonyms "]},{"cell_type":"code","execution_count":10,"metadata":{"id":"1x_FQGcI37Vg"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package omw-1.4 to\n","[nltk_data]     C:\\Users\\yan\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]},{"name":"stdout","output_type":"stream","text":["353 tweets augmented.\n","Could not augment  598 tweets.\n"]}],"source":["transformation = CompositeTransformation([WordSwapRandomCharacterSubstitution(), WordSwapQWERTY(), WordSwapWordNet(), WordSwapContract()])\n","constraints = [RepeatModification(), StopwordModification()]\n","augmenter = Augmenter(transformation=transformation, constraints=constraints, pct_words_to_swap=0.1, transformations_per_example=10)\n","print_var = 1\n","print_count = 0\n","i = 0\n","neg = 0\n","for index, row in df.iterrows():\n","  if(row[\"label\"]==1):\n","    try:\n","      text = re.sub('@\\w+', '@', row[\"text\"])\n","      text = text.replace(\"'\", \"\")\n","      l = augmenter.augment(text)\n","      for n in range(len(l)):\n","        l[n] = l[n].replace(\"@\", \"@USER____\")\n","      new_serie = pd.Series(l)\n","      X = pd.concat([X, new_serie], ignore_index=True)\n","      ade_serie = pd.Series([1]*10)\n","      y = pd.concat([y, ade_serie], ignore_index=True)\n","      i = i + 1\n","    except IndexError:\n","      neg = neg + 1\n","print(i, \"tweets augmented.\")\n","print(\"Could not augment \", neg, \"tweets.\")"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"Xf_WX8k24UWi"},"outputs":[{"data":{"text/plain":["Counter({0: 4648, 1: 4481})"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["Counter(y)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"v2scjhkxMkfJ"},"outputs":[],"source":["with open(\"1/aug.tsv\", 'wt', encoding='latin') as out_file:\n","    tsv_writer = csv.writer(out_file, delimiter='\\t')\n","    tsv_writer.writerow(['text', 'label'])\n","    for i in range(len(X)):\n","      tsv_writer.writerow([X[i], y[i]])"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["There are  4481 positive examples in this dataset.\n","There are  4648 negative examples in this dataset.\n"]}],"source":["import pandas as pd\n","import csv\n","augument3 = \"1/aug.tsv\"\n","df3 = pd.read_csv(augument3, sep='\\t', quoting=csv.QUOTE_NONE)\n","print(\"There are \", len(df3[df3[\"label\"]==1]) , \"positive examples in this dataset.\")\n","print(\"There are \", len(df3[df3[\"label\"]==0]), \"negative examples in this dataset.\")"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["text = df.text\n","label = df.label"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"H6eJeJRFE5rE"},"source":["#### Random Oversampling"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"DYmzg6oJFBCS"},"outputs":[{"name":"stdout","output_type":"stream","text":["9296\n"]},{"data":{"text/plain":["Counter({0: 4648, 1: 4648})"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["oversampler = RandomOverSampler(sampling_strategy=1)\n","X_oversampled, y_oversampled = oversampler.fit_resample(text.to_numpy().reshape(-1,1), label)\n","\n","print(len(X_oversampled))\n","Counter(y_oversampled)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"PIiKAyrjfhCC"},"outputs":[],"source":["with open(\"1/balanced_train.tsv\", 'wt', encoding='latin') as out_file:\n","    tsv_writer = csv.writer(out_file, delimiter='\\t')\n","    tsv_writer.writerow(['text', 'label'])\n","    for i in range(len(X_oversampled)):\n","      tsv_writer.writerow([X_oversampled[i][0], y_oversampled[i]])"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["There are  4648 positive examples in this dataset.\n","There are  4648 negative examples in this dataset.\n"]}],"source":["augument4 = \"1/balanced_train.tsv\"\n","df4 = pd.read_csv(augument4, sep='\\t', quoting=csv.QUOTE_NONE)\n","print(\"There are \", len(df4[df4[\"label\"]==1]) , \"positive examples in this dataset.\")\n","print(\"There are \", len(df4[df4[\"label\"]==0]), \"negative examples in this dataset.\")"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["0       @emckaymd @MedExpress He‚Äôs heading to the ER i...\n","1       Self testing day, which is always fun üò´  #Covi...\n","2       @WeissSandor @woobackbaker @Turtwigpo Oh, I'm ...\n","3       Ordered to attend a maskless MI GOP event, he ...\n","4       back working on the covid unit, last time I wa...\n","                              ...                        \n","9291    @crbarnes001 I tested positive on the 12th Jan...\n","9292    Prayers please. Currently in the ER waiting to...\n","9293    I‚Äôd like to give a big ‚Äòol üñïüèª to anyone who ev...\n","9294    I had to cancel getting my vaccine today becau...\n","9295    Just got home from donating blood towards COVI...\n","Name: text, Length: 9296, dtype: object"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["X = df4.text\n","X"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["0       0\n","1       0\n","2       0\n","3       0\n","4       1\n","       ..\n","9291    1\n","9292    1\n","9293    1\n","9294    1\n","9295    1\n","Name: label, Length: 9296, dtype: int64"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["y = df4.label\n","y"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package omw-1.4 to\n","[nltk_data]     C:\\Users\\yan\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]},{"name":"stdout","output_type":"stream","text":["1786 tweets augmented.\n","Could not augment  3813 tweets.\n"]}],"source":["transformation = CompositeTransformation([WordSwapRandomCharacterSubstitution(), WordSwapQWERTY(), WordSwapWordNet(), WordSwapContract()])\n","constraints = [RepeatModification(), StopwordModification()]\n","augmenter = Augmenter(transformation=transformation, constraints=constraints, pct_words_to_swap=0.1, transformations_per_example=10)\n","print_var = 1\n","print_count = 0\n","\n","i = 0\n","neg = 0\n","for index, row in df.iterrows():\n","  if(row[\"label\"]==1):\n","    try:\n","      text = re.sub('@\\w+', '@', row[\"text\"])\n","      text = text.replace(\"'\", \"\")\n","      l = augmenter.augment(text)\n","      for n in range(len(l)):\n","        l[n] = l[n].replace(\"@\", \"@USER____\")\n","      new_serie = pd.Series(l)\n","      X = pd.concat([X, new_serie], ignore_index=True)\n","      ade_serie = pd.Series([1]*10)\n","      y = pd.concat([y, ade_serie], ignore_index=True)\n","      i = i + 1\n","    except IndexError:\n","      neg = neg + 1\n","  else:\n","    try:\n","      text = re.sub('@\\w+', '@', row[\"text\"])\n","      text = text.replace(\"'\", \"\")\n","      l = augmenter.augment(text)\n","      for n in range(len(l)):\n","        l[n] = l[n].replace(\"@\", \"@USER____\")\n","      new_serie = pd.Series(l)\n","      X = pd.concat([X, new_serie], ignore_index=True)\n","      ade_serie = pd.Series([0]*10)\n","      y = pd.concat([y, ade_serie], ignore_index=True)\n","      i = i + 1\n","    except IndexError:\n","      neg = neg + 1\n","        \n","print(i, \"tweets augmented.\")\n","print(\"Could not augment \", neg, \"tweets.\")"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/plain":["Counter({0: 18978, 1: 8178})"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["Counter(y)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["with open(\"1/aug2.tsv\", 'wt', encoding='utf-8') as out_file:\n","    tsv_writer = csv.writer(out_file, delimiter='\\t')\n","    tsv_writer.writerow(['text', 'label'])\n","    for i in range(len(X)):\n","      tsv_writer.writerow([X[i], y[i]])"]},{"cell_type":"markdown","metadata":{},"source":["### Resample to make each class same number of samples"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["There are  8178 positive examples in this dataset.\n","There are  18978 negative examples in this dataset.\n"]}],"source":["import pandas as pd\n","import csv\n","augument5 = \"1/aug2.tsv\"\n","df5 = pd.read_csv(augument5, sep='\\t', quoting=csv.QUOTE_NONE)\n","print(\"There are \", len(df5[df5[\"label\"]==1]) , \"positive examples in this dataset.\")\n","print(\"There are \", len(df5[df5[\"label\"]==0]), \"negative examples in this dataset.\")"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["X = df5.text\n","y = df5.label"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"jgCsboMNXuio"},"source":["#### Random Undersampling"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"f3lPxgDaXykL"},"outputs":[{"name":"stdout","output_type":"stream","text":["16356\n"]},{"data":{"text/plain":["Counter({0: 8178, 1: 8178})"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["# Random Undersampler\n","\n","oversampler = RandomUnderSampler(sampling_strategy=1)\n","\n","X_undersampled, y_undersampled = oversampler.fit_resample(X.to_numpy().reshape(-1,1), y)\n","\n","print(len(X_undersampled))\n","Counter(y_undersampled)"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"TjdE-rh8YwDw"},"outputs":[],"source":["with open(\"1/finalaug.tsv\", 'wt', encoding='utf-8', newline='') as out_file:\n","    tsv_writer = csv.writer(out_file, delimiter='\\t')\n","    tsv_writer.writerow(['text', 'label'])\n","    for i in range(len(X_undersampled)):\n","      tsv_writer.writerow([X_undersampled[i][0], y_undersampled[i]])"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["combined_data = list(zip(X_undersampled, y_undersampled))\n","random.shuffle(combined_data)\n","shuffled_X, shuffled_y = zip(*combined_data)\n","\n","with open(\"1/finalaugshuffle.tsv\", 'wt', encoding='utf-8', newline='') as out_file:\n","    tsv_writer = csv.writer(out_file, delimiter='\\t')\n","    tsv_writer.writerow(['text', 'label'])\n","    for i in range(len(shuffled_X)):\n","        tsv_writer.writerow([shuffled_X[i][0], shuffled_y[i]])"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO6+GTLvZaa89JuxCGat1Ig","collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.11 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}}},"nbformat":4,"nbformat_minor":0}
